#!/usr/bin/env python3
"""Aggregate reconnaissance scan results into a single inventory file.

This utility reads output generated by different network reconnaissance tools
and merges the findings into a consolidated inventory.  The supported inputs
are:

* ``masscan`` JSON results (default path: ``out/masscan.json``)
* ``nmap`` XML output files (default directory: ``out/nmap``)
* ``theHarvester`` text exports (default directory: ``out/harvester``)

Two files are produced: a JSON inventory and a CSV inventory.  The structure of
the JSON file mirrors the columns in the CSV output, allowing the inventory to
be consumed programmatically or inspected in a spreadsheet.

Example
-------
Run the tool with default paths (useful when executing from the project root)::

    python tools/aggregate.py

Or provide explicit locations for the source and output files::

    python tools/aggregate.py \
        --nmap-dir out/custom-nmap \
        --masscan-json out/custom-masscan.json \
        --harv-dir out/custom-harvester \
        --out-json out/combined/inventory.json \
        --out-csv out/combined/inventory.csv

The script prints the paths of the generated files upon completion.
"""

import argparse
import csv
import json
import os
import xml.etree.ElementTree as ET
from typing import Dict, Iterable, List, Optional


def parse_masscan_json(path: str) -> Dict[str, Dict[str, List[int]]]:
    """Read a Masscan JSON export and return a mapping of IPs to port numbers.

    Parameters
    ----------
    path:
        Location of the JSON file produced by Masscan.  The file is expected to
        contain a list of objects with at least an ``ip`` key and, optionally, a
        ``ports`` collection.

    Returns
    -------
    dict
        Keys are IP address strings.  Values are dictionaries containing a
        ``masscan_ports`` list with the discovered port numbers in ascending
        order.  If the file is missing, empty, or malformed an empty dictionary
        is returned.
    """

    if not os.path.exists(path) or os.path.getsize(path) == 0:
        # Missing or empty Masscan output means there is nothing to merge.
        return {}

    try:
        with open(path, "r", encoding="utf-8") as file:
            masscan_results = json.load(file)
    except Exception:
        # Any parsing failure is treated as "no results" to keep the workflow
        # resilient against partially generated data.
        return {}

    hosts: Dict[str, Dict[str, List[int]]] = {}

    if isinstance(masscan_results, list):
        for entry in masscan_results:
            ip = entry.get("ip")
            if not ip:
                continue

            # Collect ports only when the dictionary contains the "port" key.
            ports = [
                port_info.get("port")
                for port_info in entry.get("ports", [])
                if "port" in port_info
            ]

            # Filter out non-numeric values, deduplicate, and store the sorted
            # list for the current host.
            hosts[ip] = {
                "masscan_ports": sorted(
                    {
                        int(port)
                        for port in ports
                        if isinstance(port, int) or str(port).isdigit()
                    }
                )
            }

    return hosts


def parse_nmap_dir(nmap_dir: str) -> Dict[str, Dict[str, Iterable[Dict[str, Optional[str]]]]]:
    """Load one or more Nmap XML files and extract host information.

    Parameters
    ----------
    nmap_dir:
        Directory containing the XML output created by Nmap.  Only ``.xml``
        files are processed.

    Returns
    -------
    dict
        A dictionary keyed by IP address with values that contain three keys:
        ``nmap_ports`` (list of port dictionaries), ``hostnames`` (list of
        resolved hostnames), and ``os`` (best-effort OS match string).
    """

    inventory: Dict[str, Dict[str, Iterable[Dict[str, Optional[str]]]]] = {}

    if not os.path.isdir(nmap_dir):
        # Without an Nmap directory there is nothing to parse, so return early.
        return inventory

    for fname in os.listdir(nmap_dir):
        if not fname.endswith(".xml"):
            continue

        xml_file = os.path.join(nmap_dir, fname)

        try:
            root = ET.parse(xml_file).getroot()
        except Exception:
            # Skip files that cannot be parsedâ€”corrupt or incomplete files
            # should not interrupt the aggregation process.
            continue

        for host in root.findall("host"):
            address: Optional[str] = None

            # Prefer IPv4/IPv6 addresses, but fall back to any available
            # address if none are explicitly tagged.
            for address_node in host.findall("address"):
                if address_node.get("addrtype") in ("ipv4", "ipv6"):
                    address = address_node.get("addr")
                    break

            if not address:
                addresses = host.findall("address")
                if addresses:
                    address = addresses[0].get("addr")

            if not address:
                continue

            info = inventory.setdefault(
                address,
                {"nmap_ports": [], "hostnames": [], "os": None},
            )

            for hostname in host.findall("hostnames/hostname"):
                name = hostname.get("name")
                if name and name not in info["hostnames"]:
                    info["hostnames"].append(name)

            osnode = host.find("os/osmatch")
            if osnode is not None and not info.get("os"):
                info["os"] = osnode.get("name")

            for port in host.findall("ports/port"):
                portnum = int(port.get("portid"))
                proto = port.get("protocol")

                state_element = port.find("state")
                state = state_element.get("state") if state_element is not None else None

                service = port.find("service")
                service_name = service.get("name") if service is not None else None

                version: Optional[str] = None
                if service is not None:
                    version_components = [
                        service.get(key)
                        for key in ("product", "version", "extrainfo")
                        if service.get(key)
                    ]
                    if version_components:
                        version = " ".join(version_components)

                info["nmap_ports"].append(
                    {
                        "port": portnum,
                        "proto": proto,
                        "state": state,
                        "service": service_name,
                        "version": version,
                    }
                )

    return inventory


def parse_harvester_dir(harv_dir: str) -> Dict[str, List[str]]:
    """Read theHarvester outputs and associate domains with discovered hosts."""

    mapping: Dict[str, List[str]] = {}

    if not os.path.isdir(harv_dir):
        return mapping

    for fname in os.listdir(harv_dir):
        path = os.path.join(harv_dir, fname)

        if os.path.isdir(path):
            continue

        domain = fname.split(".")[0]
        hosts: List[str] = []

        try:
            with open(path, "r", encoding="utf-8", errors="ignore") as file:
                for line in file:
                    candidate = line.strip()

                    # Skip likely email addresses and noisy lines by requiring a
                    # dot, a minimum length, and the absence of whitespace.
                    if "@" in candidate:
                        continue
                    if "." in candidate and len(candidate) > 5 and " " not in candidate:
                        hosts.append(candidate)
        except Exception:
            continue

        mapping[domain] = sorted(set(hosts))

    return mapping


def build_inventory(
    nmap_inv: Dict[str, Dict[str, Iterable[Dict[str, Optional[str]]]]],
    masscan_inv: Dict[str, Dict[str, List[int]]],
    harv_map: Dict[str, List[str]],
) -> Dict[str, Dict[str, Optional[Iterable]]]:
    """Merge the tool-specific outputs into a unified inventory structure."""

    inventory: Dict[str, Dict[str, Optional[Iterable]]] = {}

    # Start with Nmap results because they provide the richest context (ports,
    # services, hostnames, and OS detection).
    for ip, data in nmap_inv.items():
        inventory[ip] = {
            "ip": ip,
            "open_ports": [
                port_entry["port"]
                for port_entry in data.get("nmap_ports", [])
                if port_entry.get("state") == "open"
            ],
            "services": [
                {
                    "port": port_entry["port"],
                    "service": port_entry.get("service"),
                    "version": port_entry.get("version"),
                }
                for port_entry in data.get("nmap_ports", [])
            ],
            "hostnames": data.get("hostnames", []),
            "os": data.get("os"),
        }

    # Enrich the inventory with Masscan results to ensure fast-scan findings are
    # not lost, even if Nmap did not see those hosts.
    for ip, masscan_data in masscan_inv.items():
        if ip not in inventory:
            inventory[ip] = {
                "ip": ip,
                "open_ports": masscan_data.get("masscan_ports", []),
                "services": [],
                "hostnames": [],
                "os": None,
            }
        else:
            inventory[ip]["open_ports"] = sorted(
                set(inventory[ip].get("open_ports", []))
                | set(masscan_data.get("masscan_ports", []))
            )

    # theHarvester focuses on domain names; use its discoveries to supplement
    # hostnames for every IP address.
    for hosts in harv_map.values():
        for ip, entry in inventory.items():
            for hostname in hosts:
                if hostname not in entry["hostnames"]:
                    entry["hostnames"].append(hostname)

    return inventory


def export_json(inv: Dict[str, Dict[str, Optional[Iterable]]], outpath: str) -> None:
    """Persist the inventory as JSON so downstream tooling can reuse it."""

    with open(outpath, "w", encoding="utf-8") as file:
        json.dump(list(inv.values()), file, indent=2)


def export_csv(inv: Dict[str, Dict[str, Optional[Iterable]]], outpath: str) -> None:
    """Write a tabular view of the inventory that is easy to inspect manually."""

    with open(outpath, "w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["ip", "hostnames", "os", "open_ports", "services"])

        for ip, entry in inv.items():
            hostnames = ";".join(entry.get("hostnames", []))
            osname = entry.get("os") or ""
            ports = ";".join(str(port) for port in entry.get("open_ports", []))
            services = ";".join(
                f"{service.get('port')}:{service.get('service') or ''}:{service.get('version') or ''}"
                for service in entry.get("services", [])
            )

            writer.writerow([ip, hostnames, osname, ports, services])


def main() -> None:
    """Script entry point that wires together parsing, aggregation, and export."""

    parser = argparse.ArgumentParser(
        description=(
            "Merge Masscan, Nmap, and theHarvester outputs into JSON and CSV "
            "inventory files."
        )
    )
    parser.add_argument("--nmap-dir", default="out/nmap", help="Directory with Nmap XML files.")
    parser.add_argument("--masscan-json", default="out/masscan.json", help="Masscan JSON results file.")
    parser.add_argument(
        "--harv-dir",
        default="out/harvester",
        help="Directory containing theHarvester text exports.",
    )
    parser.add_argument("--out-json", default="out/inventory.json", help="Path for the merged JSON output.")
    parser.add_argument("--out-csv", default="out/inventory.csv", help="Path for the merged CSV output.")

    args = parser.parse_args()

    masscan_results = parse_masscan_json(args.masscan_json)
    nmap_results = parse_nmap_dir(args.nmap_dir)
    harvester_results = parse_harvester_dir(args.harv_dir)

    inventory = build_inventory(nmap_results, masscan_results, harvester_results)

    os.makedirs(os.path.dirname(args.out_json), exist_ok=True)
    export_json(inventory, args.out_json)
    export_csv(inventory, args.out_csv)

    print(f"Wrote {args.out_json} and {args.out_csv}")


if __name__ == "__main__":
    main()
