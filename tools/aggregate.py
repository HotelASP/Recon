#!/usr/bin/env python3
"""Aggregate reconnaissance artefacts into structured inventory files.

This utility reads output generated by the different stages of the reconnaissance
workflow and merges the findings into a consolidated inventory.  The supported
inputs are:

* ``masscan`` JSON results (default path: ``out/masscan/masscan.json``)
* ``smrib`` JSON logs (default path: ``out/smrib/smrib.json``)
* ``nmap`` XML output files (default directory: ``out/nmap``)
* ``nikto`` JSON exports (default directory: ``out/nikto``)
* ``theHarvester`` text exports (default directory: ``out/harvester``)
* Optional enrichment artefacts from DNS enumeration, banner grabbing, WHOIS,
  certificate transparency, Shodan, and MAC address collection (default
  directories under ``out/``)

Two files are produced: a JSON inventory and a CSV inventory.  The structure of
the JSON file mirrors the columns in the CSV output, allowing the inventory to
be consumed programmatically or inspected in a spreadsheet.

Example
-------
Run the tool with default paths (useful when executing from the project root)::

    python tools/aggregate.py

Or provide explicit locations for the source and output files::

    python tools/aggregate.py \
        --nmap-dir out/custom-nmap \
        --masscan-json out/custom-masscan/results.json \
        --harv-dir out/custom-harvester \
        --out-json out/combined/inventory.json \
        --out-csv out/combined/inventory.csv

The script prints the paths of the generated files upon completion.
"""

import argparse
import copy
import csv
import ipaddress
import json
import os
import re
import shlex
import xml.etree.ElementTree as ET
from collections import defaultdict
from pathlib import Path
from dataclasses import dataclass, field
from typing import Any, DefaultDict, Dict, Iterable, List, Mapping, NamedTuple, Optional, Sequence, Set, Tuple

try:  # pragma: no cover - runtime dependency for script execution
    from .ownership import ensure_path_owner
except ImportError:  # pragma: no cover - fallback when executed as a script
    from ownership import ensure_path_owner


def parse_masscan_json(path: str) -> Dict[str, Dict[str, List[int]]]:
    """Read a Masscan JSON export and return a mapping of IPs to port numbers.

    Parameters
    ----------
    path:
        Location of the JSON file produced by Masscan.  The file is expected to
        contain a list of objects with at least an ``ip`` key and, optionally, a
        ``ports`` collection.

    Returns
    -------
    dict
        Keys are IP address strings.  Values are dictionaries containing a
        ``masscan_ports`` list with the discovered port numbers in ascending
        order.  If the file is missing, empty, or malformed an empty dictionary
        is returned.
    """

    if not os.path.exists(path) or os.path.getsize(path) == 0:
        # Missing or empty Masscan output means there is nothing to merge.
        return {}

    try:
        with open(path, "r", encoding="utf-8") as file:
            masscan_results = json.load(file)
    except Exception:
        # Any parsing failure is treated as "no results" to keep the workflow
        # resilient against partially generated data.
        return {}

    hosts: Dict[str, Dict[str, List[int]]] = {}

    if isinstance(masscan_results, list):
        for entry in masscan_results:
            ip = entry.get("ip")
            if not ip:
                continue

            # Collect ports only when the dictionary contains the "port" key.
            ports = [
                port_info.get("port")
                for port_info in entry.get("ports", [])
                if "port" in port_info
            ]

            # Filter out non-numeric values, deduplicate, and store the sorted
            # list for the current host.
            hosts[ip] = {
                "masscan_ports": sorted(
                    {
                        int(port)
                        for port in ports
                        if isinstance(port, int) or str(port).isdigit()
                    }
                )
            }

    return hosts


def parse_smrib_json(path: str) -> Dict[str, Dict[str, List[int]]]:
    """Read an smrib JSON export and return a mapping of IPs to port numbers.

    The smrib tool does not have an officially documented JSON schema, so the
    parser is intentionally defensive.  It walks the decoded JSON structure and
    attempts to associate any values that look like IP addresses with port
    numbers contained in the same object hierarchy.

    Parameters
    ----------
    path:
        Location of the JSON log produced by ``smrib.py``.

    Returns
    -------
    dict
        Keys are IP address strings.  Values are dictionaries containing a
        ``smrib_ports`` list with the discovered port numbers in ascending
        order.
    """

    if not os.path.exists(path) or os.path.getsize(path) == 0:
        return {}

    try:
        with open(path, "r", encoding="utf-8") as file:
            data = json.load(file)
    except Exception:
        return {}

    hosts: Dict[str, Dict[str, List[int]]] = {}

    def _collect_ports(value: object) -> List[int]:
        ports: List[int] = []
        if isinstance(value, list):
            for item in value:
                ports.extend(_collect_ports(item))
        elif isinstance(value, dict):
            if "port" in value and value["port"] is not None:
                candidate = value["port"]
                if isinstance(candidate, int):
                    ports.append(candidate)
                elif isinstance(candidate, str) and candidate.isdigit():
                    ports.append(int(candidate))
            for key in ("ports", "services", "open_ports"):
                if key in value:
                    ports.extend(_collect_ports(value[key]))
            # Fall back to scanning all nested values.
            for nested in value.values():
                ports.extend(_collect_ports(nested))
        elif isinstance(value, int):
            ports.append(value)
        elif isinstance(value, str) and value.isdigit():
            ports.append(int(value))
        return ports

    def _traverse(node: object, current_ip: Optional[str] = None) -> None:
        # Walk every branch of the JSON structure because smrib does not expose a
        # stable schema. The visitor associates nearby IP address fields with the
        # ports discovered in the same portion of the tree.
        if isinstance(node, dict):
            ip_value: Optional[str] = None
            for key in ("ip", "host", "address", "ip_address"):
                candidate = node.get(key)
                if isinstance(candidate, str) and candidate.strip():
                    candidate = candidate.strip()
                    try:
                        ipaddress.ip_address(candidate)
                        ip_value = candidate
                        break
                    except ValueError:
                        continue

            ports = _collect_ports(node.get("ports")) if "ports" in node else []
            if not ports and "services" in node:
                ports = _collect_ports(node["services"])
            if not ports and "open_ports" in node:
                ports = _collect_ports(node["open_ports"])
            if not ports and "port" in node:
                ports = _collect_ports(node["port"])

            use_ip = ip_value or current_ip
            if use_ip and ports:
                entry = hosts.setdefault(use_ip, {"smrib_ports": []})
                entry.setdefault("smrib_ports", [])
                entry["smrib_ports"] = sorted(
                    set(entry["smrib_ports"]) | set(ports)
                )

            for value in node.values():
                _traverse(value, ip_value or current_ip)
        elif isinstance(node, list):
            for item in node:
                _traverse(item, current_ip)

    _traverse(data)

    return hosts


def parse_nikto_dir(path: str) -> Dict[str, Dict[int, Dict[str, Any]]]:
    """Read Nikto JSON exports and return findings organised by host/port."""

    results: Dict[str, Dict[int, Dict[str, Any]]] = {}

    if not os.path.isdir(path):
        return results

    for entry in os.listdir(path):
        if not entry.endswith(".json"):
            continue

        file_path = os.path.join(path, entry)
        try:
            with open(file_path, "r", encoding="utf-8") as handle:
                payload = json.load(handle)
        except Exception:
            continue

        records: List[Mapping[str, Any]] = []
        if isinstance(payload, dict):
            records = [payload]
        elif isinstance(payload, list):
            records = [item for item in payload if isinstance(item, Mapping)]
        else:
            continue

        for record in records:
            host = (
                record.get("ip")
                or record.get("host")
                or record.get("hostname")
                or record.get("target")
                or record.get("site")
            )
            if not isinstance(host, str) or not host.strip():
                continue
            host = host.strip()

            raw_port = (
                record.get("port")
                or record.get("targetport")
                or record.get("target_port")
                or record.get("site_port")
            )
            port: Optional[int] = None
            if isinstance(raw_port, int):
                port = raw_port
            elif isinstance(raw_port, float):
                port = int(raw_port)
            elif isinstance(raw_port, str) and raw_port.strip().isdigit():
                port = int(raw_port.strip())
            if not port or port <= 0:
                continue

            collections = []
            for key in ("vulnerabilities", "findings", "issues", "items", "vulns"):
                value = record.get(key)
                if isinstance(value, list):
                    collections = value
                    break
            if not collections and isinstance(record.get("scanresults"), list):
                collections = record.get("scanresults")  # type: ignore[assignment]
            if not collections and isinstance(record.get("vulnerability"), list):
                collections = record.get("vulnerability")  # type: ignore[assignment]

            findings: List[Dict[str, Any]] = []
            for finding in collections:
                if not isinstance(finding, Mapping):
                    continue

                description = (
                    finding.get("description")
                    or finding.get("msg")
                    or finding.get("message")
                    or finding.get("finding")
                )
                risk = finding.get("risk") or finding.get("severity") or finding.get("level")
                identifier = (
                    finding.get("id")
                    or finding.get("osvdb")
                    or finding.get("pluginid")
                    or finding.get("number")
                )
                method = finding.get("method") or finding.get("http_method")
                url = finding.get("url") or finding.get("uri") or finding.get("path")

                references: List[str] = []
                for ref_key in ("references", "refs", "links"):
                    ref_value = finding.get(ref_key)
                    if isinstance(ref_value, list):
                        references.extend(str(ref).strip() for ref in ref_value if ref)
                    elif isinstance(ref_value, str):
                        references.extend(
                            ref.strip() for ref in ref_value.replace(";", ",").split(",") if ref.strip()
                        )
                references = sorted({ref for ref in references if ref})

                entry = {
                    "description": description or "Nikto reported an issue",
                    "risk": risk,
                    "id": identifier,
                    "method": method,
                    "url": url,
                    "references": references,
                }

                banner = finding.get("banner") or record.get("banner")
                if banner:
                    entry["banner"] = banner

                findings.append(entry)

            if not findings:
                continue

            ssl_flag = False
            scheme = record.get("scheme") or record.get("protocol")
            if isinstance(scheme, str) and scheme.lower() in {"https", "ssl"}:
                ssl_flag = True
            if record.get("ssl") in (True, 1, "1", "true", "True"):
                ssl_flag = True
            if record.get("portssl") in (True, 1, "1", "true", "True"):
                ssl_flag = True

            host_entry = results.setdefault(host, {})
            port_entry = host_entry.setdefault(port, {"findings": [], "ssl": ssl_flag})
            if ssl_flag:
                port_entry["ssl"] = True

            existing = port_entry.setdefault("findings", [])
            seen_keys = {
                (item.get("description"), item.get("id"))
                for item in existing
                if isinstance(item, Mapping)
            }
            for item in findings:
                key = (item.get("description"), item.get("id"))
                if key in seen_keys:
                    continue
                existing.append(item)
                seen_keys.add(key)

    return results


def parse_nmap_dir(nmap_dir: str) -> Dict[str, Dict[str, Iterable[Dict[str, Optional[str]]]]]:
    """Load one or more Nmap XML files and extract host information.

    Parameters
    ----------
    nmap_dir:
        Directory containing the XML output created by Nmap.  Only ``.xml``
        files are processed.

    Returns
    -------
    dict
        A dictionary keyed by IP address with values that contain three keys:
        ``nmap_ports`` (list of port dictionaries), ``hostnames`` (list of
        resolved hostnames), and ``os`` (best-effort OS match string).
    """

    inventory: Dict[str, Dict[str, Iterable[Dict[str, Optional[str]]]]] = {}

    if not os.path.isdir(nmap_dir):
        # Without an Nmap directory there is nothing to parse, so return early.
        return inventory

    for fname in os.listdir(nmap_dir):
        if not fname.endswith(".xml"):
            continue

        xml_file = os.path.join(nmap_dir, fname)

        try:
            root = ET.parse(xml_file).getroot()
        except Exception:
            # Skip files that cannot be parsedâ€”corrupt or incomplete files
            # should not interrupt the aggregation process.
            continue

        for host in root.findall("host"):
            address: Optional[str] = None

            # Prefer IPv4/IPv6 addresses, but fall back to any available
            # address if none are explicitly tagged.
            for address_node in host.findall("address"):
                if address_node.get("addrtype") in ("ipv4", "ipv6"):
                    address = address_node.get("addr")
                    break

            if not address:
                addresses = host.findall("address")
                if addresses:
                    address = addresses[0].get("addr")

            if not address:
                continue

            info = inventory.setdefault(
                address,
                {"nmap_ports": [], "hostnames": [], "os": None, "os_accuracy": None},
            )

            for hostname in host.findall("hostnames/hostname"):
                name = hostname.get("name")
                if name and name not in info["hostnames"]:
                    info["hostnames"].append(name)

            osnode = host.find("os/osmatch")
            if osnode is not None and not info.get("os"):
                info["os"] = osnode.get("name")
                info["os_accuracy"] = osnode.get("accuracy")

            for port in host.findall("ports/port"):
                portnum = int(port.get("portid"))
                proto = port.get("protocol")

                state_element = port.find("state")
                state = state_element.get("state") if state_element is not None else None

                service = port.find("service")
                service_name = service.get("name") if service is not None else None

                version: Optional[str] = None
                product = None
                extrainfo = None
                tunnel = None
                banner = None
                ostype = None
                method = None
                if service is not None:
                    product = service.get("product")
                    version_value = service.get("version")
                    extrainfo = service.get("extrainfo")
                    tunnel = service.get("tunnel")
                    banner = service.get("banner") or service.get("servicefp") or service.get("fingerprint")
                    ostype = service.get("ostype")
                    method = service.get("method")
                    components = [value for value in (product, version_value, extrainfo) if value]
                    if components:
                        version = " ".join(components)

                cpes: List[str] = []
                if service is not None:
                    for cpe in service.findall("cpe"):
                        if cpe.text:
                            cpes.append(cpe.text.strip())

                scripts: List[Dict[str, Optional[str]]] = []
                for script in port.findall("script"):
                    script_id = script.get("id")
                    output = script.get("output")
                    if script_id or output:
                        scripts.append({"id": script_id, "output": output})
                    if (
                        banner is None
                        and script_id
                        and script_id.lower() == "banner"
                        and output
                    ):
                        banner = output.strip()

                info["nmap_ports"].append(
                    {
                        "port": portnum,
                        "proto": proto,
                        "state": state,
                        "reason": state_element.get("reason") if state_element is not None else None,
                        "service": service_name,
                        "version": version,
                        "product": product,
                        "extrainfo": extrainfo,
                        "tunnel": tunnel,
                        "banner": banner,
                        "ostype": ostype,
                        "method": method,
                        "cpe": cpes,
                        "scripts": scripts,
                    }
                )

    return inventory


class HarvesterFinding(NamedTuple):
    """Container describing a host discovered by theHarvester."""

    hostname: str
    ip: Optional[str]


@dataclass
class HarvesterDomainResult:
    """Structured representation of theHarvester artefacts for one domain."""

    domain: str
    findings: List[HarvesterFinding] = field(default_factory=list)
    sections: Dict[str, List[str]] = field(default_factory=dict)

    def add_section(self, name: str, values: Iterable[str]) -> None:
        canonical = _canonical_section_name(name)
        if not canonical:
            return
        bucket = self.sections.setdefault(canonical, [])
        for value in values:
            if not isinstance(value, str):
                continue
            cleaned = value.strip()
            if not cleaned or cleaned in bucket:
                continue
            bucket.append(cleaned)

    def sort_contents(self) -> None:
        self.findings = sorted(self.findings, key=lambda item: item.hostname)
        for key, items in list(self.sections.items()):
            unique = []
            for item in items:
                if item not in unique:
                    unique.append(item)
            if unique:
                self.sections[key] = sorted(unique)
            else:
                del self.sections[key]


class InventoryBundle(NamedTuple):
    """Aggregate of host inventory and theHarvester domain summaries."""

    hosts: Dict[str, Dict[str, Optional[Iterable]]]
    harvester_domains: List[Mapping[str, object]]


HARVESTER_DOMAIN_KEYS: Sequence[str] = (
    "domain",
    "target",
    "dns_domain",
    "query",
    "search",
)

HARVESTER_HOSTNAME_KEYS: Sequence[str] = (
    "host",
    "hostname",
    "domain",
    "name",
    "target",
    "fqdn",
)

HARVESTER_SECTION_ALIASES: Dict[str, Sequence[str]] = {
    "hosts": ("hosts", "host", "hostnames", "hosts found"),
    "emails": ("emails", "email", "email addresses", "email address"),
    "ips": ("ips", "ip", "ip addresses", "ip address"),
    "asns": ("asns", "asn", "asn numbers", "as numbers"),
    "interesting_urls": ("interesting urls", "interesting url", "urls", "url"),
    "linkedin_users": ("linkedin users", "linkedin user", "linkedin people", "people"),
    "linkedin_links": ("linkedin links", "linkedin link", "linkedin profiles", "linkedin profile"),
}

HARVESTER_IGNORED_SECTIONS: Sequence[str] = (
    "cmd",
    "command",
    "start",
    "end",
    "timestamp",
    "time started",
    "time finished",
    "sources",
    "source",
    "options",
    "config",
)


def _sanitise_label(label: str) -> str:
    cleaned = re.sub(r"[^0-9A-Za-z]+", " ", str(label)).strip().lower()
    return re.sub(r"\\s+", " ", cleaned)


def _canonical_section_name(label: str) -> Optional[str]:
    sanitized = _sanitise_label(label)
    if not sanitized:
        return None
    if sanitized in HARVESTER_IGNORED_SECTIONS:
        return None
    for canonical, aliases in HARVESTER_SECTION_ALIASES.items():
        if sanitized in aliases:
            return canonical
    return sanitized.replace(" ", "_")


def _normalise_section_values(value: Any) -> List[str]:
    results: List[str] = []
    if isinstance(value, bool) or value is None:
        return results
    if isinstance(value, str):
        cleaned = value.strip()
        if cleaned:
            results.append(cleaned)
    elif isinstance(value, (int, float)):
        results.append(str(value))
    elif isinstance(value, dict):
        for element in value.values():
            results.extend(_normalise_section_values(element))
    elif isinstance(value, (list, tuple, set)):
        for element in value:
            results.extend(_normalise_section_values(element))
    return results


def _collect_sections_from_json(data: Any, result: HarvesterDomainResult) -> None:
    if isinstance(data, dict):
        for key, value in data.items():
            canonical = _canonical_section_name(key)
            if canonical:
                values = _normalise_section_values(value)
                if values:
                    result.add_section(canonical, values)
            if isinstance(value, (dict, list, tuple, set)):
                _collect_sections_from_json(value, result)
    elif isinstance(data, (list, tuple, set)):
        for item in data:
            _collect_sections_from_json(item, result)


_TEXT_SECTION_HEADER = re.compile(r"^\\[\\*\\]\\s*(?P<section>[^:]+?)(?:\\s+found)?\\s*:?\\s*$", re.IGNORECASE)
_TEXT_SECTION_ITEM = re.compile(r"^\\[\\+\\]\\s*(?P<value>.+?)\\s*$")


def _parse_text_sections(content: str, result: HarvesterDomainResult) -> None:
    current_section: Optional[str] = None
    for raw_line in content.splitlines():
        line = raw_line.strip()
        if not line:
            current_section = None
            continue
        header_match = _TEXT_SECTION_HEADER.match(line)
        if header_match:
            section_label = header_match.group("section")
            if re.search(r"\\bno\\b", section_label, flags=re.IGNORECASE):
                current_section = None
                continue
            canonical = _canonical_section_name(section_label)
            current_section = canonical
            continue
        item_match = _TEXT_SECTION_ITEM.match(line)
        if item_match and current_section:
            value = item_match.group("value").strip()
            if value:
                result.add_section(current_section, [value])
            continue
        if current_section and ":" in line:
            _, _, remainder = line.partition(":")
            remainder = remainder.strip()
            if remainder:
                result.add_section(current_section, [remainder])


def _looks_like_ip(value: str) -> bool:
    try:
        ipaddress.ip_address(value)
    except ValueError:
        return False
    return True


def _normalise_hostname(raw: str) -> Optional[str]:
    candidate = raw.strip()
    if not candidate:
        return None

    # Remove URL schemes and fragments that occasionally appear in reports.
    candidate = re.sub(r"^[a-z]+://", "", candidate, flags=re.IGNORECASE)
    candidate = candidate.split("/")[0]
    candidate = candidate.split(" ")[0]

    # theHarvester may append port or IP information using a colon.  If the
    # suffix is an IP address we strip it so the hostname can be matched later.
    hostname, sep, suffix = candidate.partition(":")
    if sep and _looks_like_ip(suffix):
        candidate = hostname
    else:
        candidate = candidate.rstrip(":")

    candidate = candidate.strip().strip(".")
    candidate = candidate.lstrip("*.")
    if not candidate or " " in candidate or "@" in candidate:
        return None

    # Hostnames should have at least one dot to avoid collecting usernames or
    # other noise.
    if "." not in candidate:
        return None

    if _looks_like_ip(candidate):
        return None

    return candidate.lower()


def _extract_hostname_and_ip(entry: object) -> Optional[HarvesterFinding]:
    hostname: Optional[str] = None
    address: Optional[str] = None

    if isinstance(entry, str):
        normalised = _normalise_hostname(entry)
        if normalised:
            hostname = normalised

        # Attempt to recover an IP address when present as a suffix.
        if ":" in entry:
            maybe_host, _, maybe_ip = entry.partition(":")
            if maybe_host and maybe_ip and _looks_like_ip(maybe_ip.strip()):
                address = maybe_ip.strip()

    elif isinstance(entry, dict):
        for key in HARVESTER_HOSTNAME_KEYS:
            value = entry.get(key)
            if isinstance(value, str):
                hostname = _normalise_hostname(value)
                if hostname:
                    break

        ip_value = entry.get("ip") or entry.get("ip_address")
        if isinstance(ip_value, str) and _looks_like_ip(ip_value.strip()):
            address = ip_value.strip()

    if not hostname:
        return None

    return HarvesterFinding(hostname=hostname, ip=address)


def _extract_domain_from_command(command: str) -> Optional[str]:
    """Return the domain supplied to theHarvester ``-d`` flag, if present."""

    if not command or not command.strip():
        return None

    try:
        tokens = shlex.split(command)
    except ValueError:
        tokens = command.strip().split()

    for index, token in enumerate(tokens):
        candidate: Optional[str] = None
        normalized = token.strip()
        if not normalized:
            continue

        if normalized in {"-d", "--domain"}:
            if index + 1 < len(tokens):
                candidate = tokens[index + 1]
        elif normalized.startswith("--domain="):
            candidate = normalized.split("=", 1)[1]
        elif normalized.startswith("-d") and normalized != "-d":
            candidate = normalized[2:]

        if candidate:
            cleaned = _normalise_hostname(candidate)
            if cleaned:
                return cleaned

    return None


def _extract_domain_from_metadata(metadata: object, fallback: str) -> str:
    if isinstance(metadata, dict):
        for key in HARVESTER_DOMAIN_KEYS:
            value = metadata.get(key)
            if isinstance(value, str) and value.strip():
                return value.strip().lower()
            if isinstance(value, dict):
                nested = _extract_domain_from_metadata(value, fallback)
                if nested:
                    return nested

        derived = _extract_domain_from_command(str(metadata.get("cmd", "")))
        if derived:
            return derived

    if isinstance(metadata, str) and metadata.strip():
        return metadata.strip().lower()

    return fallback.lower()


def parse_harvester_dir(harv_dir: str) -> Dict[str, HarvesterDomainResult]:
    """Read theHarvester outputs and associate domains with discovered hosts."""

    mapping: Dict[str, HarvesterDomainResult] = {}
    global_ip_registry: Dict[str, str] = {}

    if not os.path.isdir(harv_dir):
        return mapping

    for fname in os.listdir(harv_dir):
        path = os.path.join(harv_dir, fname)

        if os.path.isdir(path):
            continue

        domain_hint = os.path.splitext(fname)[0].lower()

        try:
            with open(path, "r", encoding="utf-8", errors="ignore") as file:
                content = file.read()
        except Exception:
            continue

        domain_result = HarvesterDomainResult(domain=domain_hint)

        try:
            data = json.loads(content)
        except json.JSONDecodeError:
            data = None

        if isinstance(data, dict):
            domain_result.domain = _extract_domain_from_metadata(data, domain_hint)

            raw_hosts: Sequence[object] = []
            if isinstance(data.get("hosts"), list):
                raw_hosts = data["hosts"]
            elif isinstance(data.get("hosts"), dict):
                raw_hosts = list(data["hosts"].values())

            if not raw_hosts and isinstance(data.get("data"), dict):
                nested_hosts = data["data"].get("hosts")
                if isinstance(nested_hosts, list):
                    raw_hosts = nested_hosts

            for entry in raw_hosts:
                finding = _extract_hostname_and_ip(entry)
                if finding:
                    domain_result.findings.append(finding)

            stack: List[object] = [data]
            while stack:
                current = stack.pop()
                finding = _extract_hostname_and_ip(current)
                if finding:
                    domain_result.findings.append(finding)

                if isinstance(current, dict):
                    stack.extend(current.values())
                elif isinstance(current, list):
                    stack.extend(current)

            _collect_sections_from_json(data, domain_result)

        if not domain_result.findings:
            for line in content.splitlines():
                finding = _extract_hostname_and_ip(line)
                if finding:
                    domain_result.findings.append(finding)

        _parse_text_sections(content, domain_result)

        deduped: Dict[str, HarvesterFinding] = {}
        local_ip_registry: Dict[str, str] = {}
        for finding in domain_result.findings:
            host_key = finding.hostname
            ip_normalised: Optional[str] = None
            if finding.ip:
                try:
                    ip_normalised = str(ipaddress.ip_address(finding.ip.strip()))
                except ValueError:
                    ip_normalised = None

            if ip_normalised:
                existing_global = global_ip_registry.get(ip_normalised)
                if existing_global and existing_global != host_key:
                    continue
                existing_local = local_ip_registry.get(ip_normalised)
                if existing_local and existing_local != host_key:
                    continue

            existing = deduped.get(host_key)
            if existing is None or (existing.ip is None and finding.ip):
                deduped[host_key] = finding
                if ip_normalised:
                    local_ip_registry[ip_normalised] = host_key

        domain_result.findings = list(deduped.values())
        for ip_normalised, host_key in local_ip_registry.items():
            global_ip_registry[ip_normalised] = host_key
        domain_result.sort_contents()

        has_sections = any(values for values in domain_result.sections.values())
        if not domain_result.findings and not has_sections:
            continue

        mapping[domain_result.domain] = domain_result

    return mapping


def _load_json_file(path: Path) -> Optional[Mapping[str, object]]:
    try:
        with path.open("r", encoding="utf-8") as handle:
            data = json.load(handle)
    except Exception:
        return None
    if isinstance(data, Mapping):
        return data
    return None


def parse_dns_dir(path: str) -> Dict[str, Dict[str, Any]]:
    results: Dict[str, Dict[str, Any]] = {}
    directory = Path(path)
    if not directory.is_dir():
        return results

    for candidate in directory.iterdir():
        if candidate.is_dir():
            continue
        data = _load_json_file(candidate)
        if not data:
            continue
        domain = data.get("domain") or candidate.stem
        if not isinstance(domain, str):
            continue
        domain_lower = domain.strip().lower()
        if not domain_lower:
            continue

        payload: Dict[str, Any] = {}
        records = data.get("records")
        if isinstance(records, Mapping):
            normalised: Dict[str, List[str]] = {}
            for key, values in records.items():
                if not isinstance(key, str):
                    continue
                if isinstance(values, list):
                    cleaned = sorted(
                        {
                            str(value).strip()
                            for value in values
                            if isinstance(value, (str, int, float)) and str(value).strip()
                        }
                    )
                elif isinstance(values, (str, int, float)):
                    cleaned = [str(values).strip()]
                else:
                    cleaned = []
                if cleaned:
                    normalised[key.lower()] = cleaned
            if normalised:
                payload["records"] = normalised

        errors = data.get("errors")
        if isinstance(errors, list) and errors:
            payload["errors"] = [str(item) for item in errors if item]
        resolvers = data.get("resolvers")
        if isinstance(resolvers, list) and resolvers:
            payload["resolvers"] = [str(item) for item in resolvers if item]
        timestamp = data.get("timestamp")
        if isinstance(timestamp, str) and timestamp.strip():
            payload["timestamp"] = timestamp.strip()

        if payload:
            results[domain_lower] = payload

    return results


def parse_banner_dir(path: str) -> Dict[str, Dict[str, Any]]:
    results: Dict[str, Dict[str, Any]] = {}
    directory = Path(path)
    if not directory.is_dir():
        return results

    for candidate in directory.iterdir():
        if candidate.is_dir():
            continue
        data = _load_json_file(candidate)
        if not data:
            continue
        domain = data.get("domain") or candidate.stem
        if not isinstance(domain, str):
            continue
        domain_lower = domain.strip().lower()
        if not domain_lower:
            continue

        payload: Dict[str, Any] = {}
        banners = data.get("banners")
        if isinstance(banners, list):
            cleaned_banners: List[Dict[str, Any]] = []
            for entry in banners:
                if not isinstance(entry, Mapping):
                    continue
                banner_entry: Dict[str, Any] = {}
                for key in ("port", "protocol", "status", "reason", "server", "banner", "error"):
                    value = entry.get(key)
                    if value is not None:
                        banner_entry[key] = value
                headers = entry.get("headers")
                if isinstance(headers, Mapping):
                    header_map = {
                        str(hkey): str(hval)
                        for hkey, hval in headers.items()
                        if isinstance(hkey, str) and isinstance(hval, str)
                    }
                    if header_map:
                        banner_entry["headers"] = header_map
                if banner_entry:
                    cleaned_banners.append(banner_entry)
            if cleaned_banners:
                payload["banners"] = cleaned_banners

        timestamp = data.get("timestamp")
        if isinstance(timestamp, str) and timestamp.strip():
            payload["timestamp"] = timestamp.strip()

        if payload:
            results[domain_lower] = payload

    return results


def parse_whois_dir(path: str) -> Dict[str, Dict[str, Any]]:
    results: Dict[str, Dict[str, Any]] = {}
    directory = Path(path)
    if not directory.is_dir():
        return results

    for candidate in directory.iterdir():
        if candidate.is_dir():
            continue
        data = _load_json_file(candidate)
        if not data:
            continue
        domain = data.get("domain") or candidate.stem
        if not isinstance(domain, str):
            continue
        domain_lower = domain.strip().lower()
        if not domain_lower:
            continue

        payload: Dict[str, Any] = {}
        for key in ("whois_server", "timestamp"):
            value = data.get(key)
            if isinstance(value, str) and value.strip():
                payload[key] = value.strip()
        parsed = data.get("parsed")
        if isinstance(parsed, Mapping) and parsed:
            payload["parsed"] = {str(k): v for k, v in parsed.items() if v is not None}
        raw_response = data.get("raw_response")
        if isinstance(raw_response, str) and raw_response.strip():
            payload["raw_response"] = raw_response
        errors = data.get("errors")
        if isinstance(errors, list) and errors:
            payload["errors"] = [str(item) for item in errors if item]

        if payload:
            results[domain_lower] = payload

    return results


def parse_ct_dir(path: str) -> Dict[str, Dict[str, Any]]:
    results: Dict[str, Dict[str, Any]] = {}
    directory = Path(path)
    if not directory.is_dir():
        return results

    for candidate in directory.iterdir():
        if candidate.is_dir():
            continue
        data = _load_json_file(candidate)
        if not data:
            continue
        domain = data.get("domain") or candidate.stem
        if not isinstance(domain, str):
            continue
        domain_lower = domain.strip().lower()
        if not domain_lower:
            continue

        payload: Dict[str, Any] = {}
        entries = data.get("entries")
        if isinstance(entries, list):
            cleaned_entries: List[Dict[str, Any]] = []
            for entry in entries:
                if not isinstance(entry, Mapping):
                    continue
                record: Dict[str, Any] = {}
                for key in ("name", "issuer", "not_before", "not_after", "entry_timestamp", "min_cert_id"):
                    value = entry.get(key)
                    if value is not None:
                        record[key] = value
                if record:
                    cleaned_entries.append(record)
            if cleaned_entries:
                payload["entries"] = cleaned_entries
        if data.get("source"):
            payload["source"] = data.get("source")
        timestamp = data.get("timestamp")
        if isinstance(timestamp, str) and timestamp.strip():
            payload["timestamp"] = timestamp.strip()
        error = data.get("error")
        if isinstance(error, str) and error.strip():
            payload["error"] = error.strip()

        if payload:
            results[domain_lower] = payload

    return results


def parse_mac_dir(path: str) -> Dict[str, Dict[str, Any]]:
    results: Dict[str, Dict[str, Any]] = {}
    directory = Path(path)
    if not directory.is_dir():
        return results

    for candidate in directory.iterdir():
        if candidate.is_dir():
            continue
        data = _load_json_file(candidate)
        if not data:
            continue

        domain = data.get("domain") or candidate.stem
        if not isinstance(domain, str):
            continue
        domain_lower = domain.strip().lower()
        if not domain_lower:
            continue

        payload: Dict[str, Any] = {}
        addresses = data.get("mac_addresses")
        if isinstance(addresses, list):
            cleaned_addresses: List[Dict[str, Any]] = []
            for entry in addresses:
                if not isinstance(entry, Mapping):
                    continue
                record: Dict[str, Any] = {}
                address = entry.get("address") or entry.get("mac_address")
                if isinstance(address, str) and address.strip():
                    record["address"] = address.strip().upper()
                else:
                    continue
                vendor = entry.get("vendor")
                if isinstance(vendor, str) and vendor.strip():
                    record["vendor"] = vendor.strip()
                occurrences = entry.get("occurrences")
                if isinstance(occurrences, list):
                    cleaned_occurrences: List[Dict[str, Any]] = []
                    for occ in occurrences:
                        if not isinstance(occ, Mapping):
                            continue
                        occ_entry: Dict[str, Any] = {}
                        for key in ("source", "file", "path", "value", "line", "match"):
                            value = occ.get(key)
                            if isinstance(value, str) and value.strip():
                                occ_entry[key] = value.strip()
                        lineno = occ.get("lineno")
                        if isinstance(lineno, int):
                            occ_entry["lineno"] = lineno
                        elif isinstance(lineno, str) and lineno.strip().isdigit():
                            occ_entry["lineno"] = int(lineno.strip())
                        if occ_entry:
                            cleaned_occurrences.append(occ_entry)
                    if cleaned_occurrences:
                        record["occurrences"] = cleaned_occurrences
                cleaned_addresses.append(record)
            if cleaned_addresses:
                payload["mac_addresses"] = cleaned_addresses

        context = data.get("context")
        if isinstance(context, Mapping) and context:
            context_payload: Dict[str, Any] = {}
            hosts = context.get("hosts")
            if isinstance(hosts, list) and hosts:
                context_payload["hosts"] = [str(host) for host in hosts if host]
            ips = context.get("ips")
            if isinstance(ips, list) and ips:
                context_payload["ips"] = [str(ip) for ip in ips if ip]
            sections = context.get("sections")
            if isinstance(sections, Mapping):
                section_payload: Dict[str, List[str]] = {}
                for key, values in sections.items():
                    if not isinstance(key, str) or not isinstance(values, list):
                        continue
                    cleaned_values = [str(value) for value in values if value]
                    if cleaned_values:
                        section_payload[key] = cleaned_values
                if section_payload:
                    context_payload["sections"] = section_payload
            if context_payload:
                payload["context"] = context_payload

        timestamp = data.get("timestamp")
        if isinstance(timestamp, str) and timestamp.strip():
            payload["timestamp"] = timestamp.strip()

        if payload:
            results[domain_lower] = payload

    return results


def parse_shodan_dir(path: str) -> Dict[str, Dict[str, Any]]:
    results: Dict[str, Dict[str, Any]] = {}
    directory = Path(path)
    if not directory.is_dir():
        return results

    for candidate in directory.iterdir():
        if candidate.is_dir():
            continue
        data = _load_json_file(candidate)
        if not data:
            continue
        ip_value = data.get("ip") or candidate.stem
        if not isinstance(ip_value, str):
            continue
        ip_clean = ip_value.strip()
        if not ip_clean:
            continue

        payload: Dict[str, Any] = {}
        summary = data.get("summary")
        if isinstance(summary, Mapping):
            summary_payload: Dict[str, Any] = {}
            for key in (
                "ip",
                "org",
                "os",
                "isp",
                "asn",
                "city",
                "country",
                "last_update",
            ):
                value = summary.get(key)
                if value is not None:
                    summary_payload[key] = value
            ports = summary.get("ports")
            if isinstance(ports, list):
                summary_payload["ports"] = [
                    int(port)
                    for port in ports
                    if isinstance(port, int) or (isinstance(port, str) and str(port).isdigit())
                ]
            hostnames = summary.get("hostnames")
            if isinstance(hostnames, list):
                summary_payload["hostnames"] = [
                    str(name) for name in hostnames if isinstance(name, str) and name
                ]
            tags = summary.get("tags")
            if isinstance(tags, list):
                summary_payload["tags"] = [str(tag) for tag in tags if tag]
            vulns = summary.get("vulns")
            if isinstance(vulns, list):
                summary_payload["vulns"] = [str(item) for item in vulns if item]
            services = summary.get("services")
            if isinstance(services, list):
                cleaned_services: List[Dict[str, Any]] = []
                for entry in services:
                    if not isinstance(entry, Mapping):
                        continue
                    service_entry: Dict[str, Any] = {}
                    for key in ("port", "transport", "product", "version", "timestamp", "data"):
                        value = entry.get(key)
                        if value is not None:
                            service_entry[key] = value
                    cpe_values = entry.get("cpe")
                    if isinstance(cpe_values, list):
                        service_entry["cpe"] = [str(cpe) for cpe in cpe_values if cpe]
                    if service_entry:
                        cleaned_services.append(service_entry)
                if cleaned_services:
                    summary_payload["services"] = cleaned_services
            if summary_payload:
                payload["summary"] = summary_payload

        error = data.get("error")
        if isinstance(error, str) and error.strip():
            payload["error"] = error.strip()
        timestamp = data.get("timestamp")
        if isinstance(timestamp, str) and timestamp.strip():
            payload["timestamp"] = timestamp.strip()

        if payload:
            results[ip_clean] = payload

    return results


def build_inventory(
    nmap_inv: Dict[str, Dict[str, Iterable[Dict[str, Optional[str]]]]],
    nikto_inv: Dict[str, Dict[int, Dict[str, Any]]],
    masscan_inv: Dict[str, Dict[str, List[int]]],
    smrib_inv: Dict[str, Dict[str, List[int]]],
    harv_map: Dict[str, HarvesterDomainResult],
    dns_inv: Dict[str, Dict[str, Any]],
    banner_inv: Dict[str, Dict[str, Any]],
    whois_inv: Dict[str, Dict[str, Any]],
    ct_inv: Dict[str, Dict[str, Any]],
    mac_inv: Dict[str, Dict[str, Any]],
    shodan_inv: Dict[str, Dict[str, Any]],
) -> InventoryBundle:
    """Merge the tool-specific outputs into a unified inventory structure."""

    inventory: Dict[str, Dict[str, Optional[Iterable]]] = {}
    domain_to_hosts: DefaultDict[str, Set[str]] = defaultdict(set)

    def _ensure_host_entry(ip: str) -> Dict[str, Optional[Iterable]]:
        return inventory.setdefault(
            ip,
            {
                "ip": ip,
                "entry_type": "host",
                "open_ports": [],
                "services": [],
                "hostnames": [],
                "os": None,
                "os_accuracy": None,
                "related_domains": [],
            },
        )

    def _record_domain_host_association(domain_lower: str, ip: Optional[str]) -> None:
        if not domain_lower or not ip:
            return
        domain_to_hosts[domain_lower].add(ip)

    def _assign_domain_enrichment(domain_lower: str, key: str, value: Mapping[str, Any]) -> None:
        if not domain_lower or not isinstance(value, Mapping):
            return
        hosts = domain_to_hosts.get(domain_lower)
        if not hosts:
            return
        for host_ip in sorted(hosts):
            entry = _ensure_host_entry(host_ip)
            enrichment = entry.setdefault("enrichment", {})
            domains_section = enrichment.setdefault("domains", {})
            domain_entry = domains_section.setdefault(domain_lower, {})
            domain_entry[key] = copy.deepcopy(value)

    # Start with Nmap results because they provide the richest context (ports,
    # services, hostnames, and OS detection).
    for ip, data in nmap_inv.items():
        inventory[ip] = {
            "ip": ip,
            "entry_type": "host",
            "open_ports": sorted(
                {
                    port_entry["port"]
                    for port_entry in data.get("nmap_ports", [])
                    if port_entry.get("state") == "open"
                }
            ),
            "services": [
                {
                    "port": port_entry.get("port"),
                    "proto": port_entry.get("proto"),
                    "state": port_entry.get("state"),
                    "reason": port_entry.get("reason"),
                    "service": port_entry.get("service"),
                    "version": port_entry.get("version"),
                    "product": port_entry.get("product"),
                    "extrainfo": port_entry.get("extrainfo"),
                    "tunnel": port_entry.get("tunnel"),
                    "banner": port_entry.get("banner"),
                    "ostype": port_entry.get("ostype"),
                    "method": port_entry.get("method"),
                    "cpe": port_entry.get("cpe", []),
                    "scripts": port_entry.get("scripts", []),
                }
                for port_entry in data.get("nmap_ports", [])
            ],
            "hostnames": sorted(set(data.get("hostnames", []))),
            "os": data.get("os"),
            "os_accuracy": data.get("os_accuracy"),
            "related_domains": [],
        }

    # Enrich the inventory with Masscan results to ensure fast-scan findings are
    # not lost, even if Nmap did not see those hosts.
    for ip, masscan_data in masscan_inv.items():
        if ip not in inventory:
            inventory[ip] = {
                "ip": ip,
                "entry_type": "host",
                "open_ports": masscan_data.get("masscan_ports", []),
                "services": [],
                "hostnames": [],
                "os": None,
                "os_accuracy": None,
                "related_domains": [],
            }
        else:
            inventory[ip]["open_ports"] = sorted(
                set(inventory[ip].get("open_ports", []))
                | set(masscan_data.get("masscan_ports", []))
            )

    for ip, port_map in nikto_inv.items():
        entry = inventory.setdefault(
            ip,
            {
                "ip": ip,
                "entry_type": "host",
                "open_ports": [],
                "services": [],
                "hostnames": [],
                "os": None,
                "os_accuracy": None,
                "related_domains": [],
            },
        )

        entry_ports = set(entry.get("open_ports", []))
        services = entry.setdefault("services", [])

        for port, details in port_map.items():
            if not isinstance(port, int):
                continue
            entry_ports.add(port)
            ssl_flag = bool(details.get("ssl")) if isinstance(details, Mapping) else False
            findings: List[Mapping[str, Any]] = []
            if isinstance(details, Mapping):
                raw_findings = details.get("findings")
                if isinstance(raw_findings, list):
                    findings = [item for item in raw_findings if isinstance(item, Mapping)]
            if not findings:
                continue

            service_entry: Optional[Dict[str, Any]] = None
            for service in services:
                if isinstance(service, dict) and service.get("port") == port:
                    service_entry = service
                    break

            if service_entry is None:
                service_entry = {
                    "port": port,
                    "proto": "tcp",
                    "state": "open",
                    "reason": None,
                    "service": "http",
                    "version": None,
                    "product": None,
                    "extrainfo": None,
                    "tunnel": "ssl" if ssl_flag else None,
                    "banner": None,
                    "ostype": None,
                    "method": None,
                    "cpe": [],
                    "scripts": [],
                }
                services.append(service_entry)
            else:
                if ssl_flag and not service_entry.get("tunnel"):
                    service_entry["tunnel"] = "ssl"
                if not service_entry.get("service"):
                    service_entry["service"] = "http"
                if not service_entry.get("proto"):
                    service_entry["proto"] = "tcp"
                if not service_entry.get("state"):
                    service_entry["state"] = "open"

            existing_findings = service_entry.setdefault("nikto_findings", [])
            seen = {
                (item.get("description"), item.get("id"))
                for item in existing_findings
                if isinstance(item, Mapping)
            }
            for finding in findings:
                key = (finding.get("description"), finding.get("id"))
                if key in seen:
                    continue
                existing_findings.append(finding)
                seen.add(key)

        entry["open_ports"] = sorted(entry_ports)

    # Merge smrib discoveries so that ports identified by that scanner are
    # reflected even if Nmap and Masscan missed them.
    for ip, smrib_data in smrib_inv.items():
        if ip not in inventory:
            inventory[ip] = {
                "ip": ip,
                "entry_type": "host",
                "open_ports": smrib_data.get("smrib_ports", []),
                "services": [],
                "hostnames": [],
                "os": None,
                "os_accuracy": None,
                "related_domains": [],
            }
        else:
            inventory[ip]["open_ports"] = sorted(
                set(inventory[ip].get("open_ports", []))
                | set(smrib_data.get("smrib_ports", []))
            )

    domain_summaries: Dict[str, Dict[str, Any]] = {}

    def _ensure_domain_summary(domain_lower: str) -> Dict[str, Any]:
        domain_to_hosts.setdefault(domain_lower, set())
        return domain_summaries.setdefault(
            domain_lower,
            {
                "domain": domain_lower,
                "hosts": [],
                "ips": [],
                "host_records": [],
                "sections": {},
            },
        )

    for domain_key in sorted(harv_map.keys()):
        result = harv_map[domain_key]
        domain_lower = result.domain.lower()
        domain_suffix = f".{domain_lower}"

        summary = _ensure_domain_summary(domain_lower)

        host_records = [
            {"hostname": finding.hostname, "ip": finding.ip}
            for finding in result.findings
        ]
        if host_records:
            summary.setdefault("host_records", []).extend(host_records)

        hostnames_for_domain = [record["hostname"] for record in host_records if record.get("hostname")]
        ips_for_domain = [record["ip"] for record in host_records if record.get("ip")]

        sections = summary.setdefault("sections", {})
        section_snapshot = {
            key: list(values)
            for key, values in result.sections.items()
        }
        if hostnames_for_domain:
            section_snapshot.setdefault("hosts", [])
            section_snapshot["hosts"].extend(hostnames_for_domain)
        if ips_for_domain:
            section_snapshot.setdefault("ips", [])
            section_snapshot["ips"].extend(ips_for_domain)

        summary.setdefault("hosts", []).extend(hostnames_for_domain)
        summary.setdefault("ips", []).extend(ips_for_domain)

        for key, values in section_snapshot.items():
            bucket = sections.setdefault(key, [])
            for value in values:
                if value and value not in bucket:
                    bucket.append(value)

        # Track every host already known in the consolidated inventory so their
        # records can be enriched with theHarvester context extracted for the
        # current domain.
        associated_ips = {
            finding.ip
            for finding in result.findings
            if finding.ip and finding.ip in inventory
        }

        if not associated_ips:
            # When theHarvester surfaces hostnames that have not yet been tied to
            # an IP in the inventory, search for partial matches (e.g. domains or
            # subdomains) across the hostnames that Nmap reported. This captures
            # infrastructure that resolves dynamically or is shared across hosts.
            candidate_hostnames = {finding.hostname.lower() for finding in result.findings}
            for ip, entry in inventory.items():
                existing = [name.lower() for name in entry.get("hostnames", [])]
                if any(
                    (
                        hn == domain_lower
                        or hn.endswith(domain_suffix)
                        or hn in candidate_hostnames
                    )
                    for hn in existing
                ):
                    associated_ips.add(ip)

        aggregated_sections = {
            key: sorted({value for value in values if value})
            for key, values in section_snapshot.items()
        }

        for target_ip in associated_ips:
            entry = inventory[target_ip]
            hostnames = entry.setdefault("hostnames", [])
            for hostname in hostnames_for_domain:
                if hostname and hostname not in hostnames:
                    hostnames.append(hostname)
            related = entry.setdefault("related_domains", [])
            if domain_lower not in related:
                related.append(domain_lower)
            _record_domain_host_association(domain_lower, target_ip)

            harv_entry = entry.setdefault("harvester", {})
            domains_list = harv_entry.setdefault("domains", [])
            if domain_lower not in domains_list:
                domains_list.append(domain_lower)
            for section_name, values in aggregated_sections.items():
                dest = harv_entry.setdefault(section_name, [])
                for value in values:
                    if value not in dest:
                        dest.append(value)

    for domain_lower, info in dns_inv.items():
        summary = _ensure_domain_summary(domain_lower)
        enrichment = summary.setdefault("enrichment", {})
        enrichment["dns_records"] = info
        records = info.get("records")
        if isinstance(records, Mapping):
            for key in ("a", "aaaa"):
                values = records.get(key)
                if isinstance(values, list):
                    for value in values:
                        candidate = str(value).strip()
                        if not candidate:
                            continue
                        summary.setdefault("ips", []).append(candidate)
                        try:
                            normalised = str(ipaddress.ip_address(candidate))
                        except ValueError:
                            continue
                        host_entry = _ensure_host_entry(normalised)
                        related = host_entry.setdefault("related_domains", [])
                        if domain_lower not in related:
                            related.append(domain_lower)
                        _record_domain_host_association(domain_lower, normalised)
        _assign_domain_enrichment(domain_lower, "dns_records", info)

    for domain_lower, info in banner_inv.items():
        summary = _ensure_domain_summary(domain_lower)
        enrichment = summary.setdefault("enrichment", {})
        enrichment["banners"] = info
        _assign_domain_enrichment(domain_lower, "banners", info)

    for domain_lower, info in whois_inv.items():
        summary = _ensure_domain_summary(domain_lower)
        enrichment = summary.setdefault("enrichment", {})
        enrichment["whois"] = info
        _assign_domain_enrichment(domain_lower, "whois", info)

    for domain_lower, info in ct_inv.items():
        summary = _ensure_domain_summary(domain_lower)
        enrichment = summary.setdefault("enrichment", {})
        enrichment["certificate_transparency"] = info
        _assign_domain_enrichment(domain_lower, "certificate_transparency", info)

    for domain_lower, info in mac_inv.items():
        summary = _ensure_domain_summary(domain_lower)
        enrichment = summary.setdefault("enrichment", {})
        enrichment["mac_addresses"] = info
        context = info.get("context") if isinstance(info, Mapping) else None
        if isinstance(context, Mapping):
            ips = context.get("ips")
            if isinstance(ips, list):
                for item in ips:
                    try:
                        normalised_ip = str(ipaddress.ip_address(str(item).strip()))
                    except ValueError:
                        continue
                    _ensure_host_entry(normalised_ip)
                    _record_domain_host_association(domain_lower, normalised_ip)
            hosts_ctx = context.get("hosts")
            if isinstance(hosts_ctx, list):
                candidate_hosts = {
                    host.strip().lower()
                    for host in hosts_ctx
                    if isinstance(host, str) and host.strip()
                }
                if candidate_hosts:
                    for ip, entry in inventory.items():
                        hostnames = entry.get("hostnames", [])
                        if any(
                            isinstance(name, str) and name.strip().lower() in candidate_hosts
                            for name in hostnames
                        ):
                            _record_domain_host_association(domain_lower, ip)
        _assign_domain_enrichment(domain_lower, "mac_addresses", info)

    for ip, info in shodan_inv.items():
        host_entry = _ensure_host_entry(ip)
        shodan_entry = host_entry.setdefault("shodan", {})
        summary_data = info.get("summary")
        if isinstance(summary_data, Mapping):
            for key, value in summary_data.items():
                if key == "ports" and isinstance(value, list):
                    ports = {
                        int(port)
                        for port in value
                        if isinstance(port, int) or (isinstance(port, str) and str(port).isdigit())
                    }
                    host_entry["open_ports"] = sorted(
                        set(host_entry.get("open_ports", [])) | ports
                    )
                    shodan_entry[key] = sorted(ports)
                elif key == "hostnames" and isinstance(value, list):
                    hostnames = host_entry.setdefault("hostnames", [])
                    for name in value:
                        if isinstance(name, str) and name and name not in hostnames:
                            hostnames.append(name)
                    shodan_entry[key] = [str(name) for name in value if isinstance(name, str) and name]
                else:
                    shodan_entry[key] = value
        error = info.get("error")
        if isinstance(error, str) and error.strip():
            shodan_entry["error"] = error.strip()
        timestamp = info.get("timestamp")
        if isinstance(timestamp, str) and timestamp.strip():
            shodan_entry.setdefault("timestamp", timestamp.strip())

    for entry in inventory.values():
        entry["hostnames"] = sorted({name for name in entry.get("hostnames", []) if name})
        entry["related_domains"] = sorted(
            {domain for domain in entry.get("related_domains", []) if domain}
        )
        harv_data = entry.get("harvester")
        if isinstance(harv_data, dict):
            for key, values in list(harv_data.items()):
                if isinstance(values, list):
                    harv_data[key] = sorted({value for value in values if value})

        enrichment_data = entry.get("enrichment")
        if isinstance(enrichment_data, dict):
            domains_section = enrichment_data.get("domains")
            if isinstance(domains_section, dict):
                cleaned_domains: Dict[str, Dict[str, Any]] = {}
                for domain_key, domain_info in domains_section.items():
                    if not isinstance(domain_key, str):
                        continue
                    if isinstance(domain_info, Mapping):
                        cleaned_domains[domain_key] = domain_info
                if cleaned_domains:
                    enrichment_data["domains"] = dict(sorted(cleaned_domains.items()))
                else:
                    enrichment_data.pop("domains", None)
            if not enrichment_data:
                entry.pop("enrichment", None)

    domain_summary_list: List[Dict[str, Any]] = []
    for domain_lower, summary in domain_summaries.items():
        hosts_list = sorted({name for name in summary.get("hosts", []) if name})
        ips_list = sorted({ip for ip in summary.get("ips", []) if ip})
        summary["hosts"] = hosts_list
        summary["ips"] = ips_list

        raw_records = summary.get("host_records") or []
        cleaned_records: List[Dict[str, Any]] = []
        if isinstance(raw_records, list):
            seen_pairs: Set[Tuple[Optional[str], Optional[str]]] = set()
            for record in raw_records:
                if not isinstance(record, Mapping):
                    continue
                hostname = record.get("hostname")
                ip_value = record.get("ip")
                key = (hostname, ip_value)
                if key in seen_pairs:
                    continue
                seen_pairs.add(key)
                cleaned_record: Dict[str, Any] = {}
                if hostname:
                    cleaned_record["hostname"] = hostname
                if ip_value:
                    cleaned_record["ip"] = ip_value
                if cleaned_record:
                    cleaned_records.append(cleaned_record)
        if cleaned_records:
            summary["host_records"] = cleaned_records
        else:
            summary.pop("host_records", None)

        sections = summary.get("sections")
        if isinstance(sections, dict):
            cleaned_sections: Dict[str, List[str]] = {}
            for key, values in sections.items():
                if not isinstance(values, list):
                    continue
                cleaned_values = sorted({value for value in values if value})
                if cleaned_values:
                    cleaned_sections[key] = cleaned_values
            summary["sections"] = cleaned_sections
        else:
            summary["sections"] = {}

        enrichment = summary.get("enrichment")
        if isinstance(enrichment, dict):
            summary["enrichment"] = {
                key: value
                for key, value in enrichment.items()
                if value is not None
            }
        else:
            summary.pop("enrichment", None)

        if (
            hosts_list
            or ips_list
            or summary.get("sections")
            or summary.get("host_records")
            or summary.get("enrichment")
        ):
            domain_summary_list.append(summary)

    domain_summary_list = sorted(domain_summary_list, key=lambda item: item.get("domain", ""))

    return InventoryBundle(hosts=inventory, harvester_domains=domain_summary_list)


def export_json(bundle: InventoryBundle, outpath: str) -> None:
    """Persist the inventory as JSON so downstream tooling can reuse it."""

    def _sort_key(ip: str) -> tuple:
        try:
            return (0, ipaddress.ip_address(ip))
        except ValueError:
            return (1, ip)

    hosts = [
        bundle.hosts[ip]
        for ip in sorted(bundle.hosts.keys(), key=_sort_key)
    ]
    payload: Dict[str, object] = {"hosts": hosts}
    if bundle.harvester_domains:
        payload["harvester_domains"] = bundle.harvester_domains

    with open(outpath, "w", encoding="utf-8") as file:
        json.dump(payload, file, indent=2)
    ensure_path_owner(Path(outpath))


def export_csv(bundle: InventoryBundle, outpath: str) -> None:
    """Write a tabular view of the inventory that is easy to inspect manually."""

    def _sort_key(ip: str) -> tuple:
        try:
            return (0, ipaddress.ip_address(ip))
        except ValueError:
            return (1, ip)

    with open(outpath, "w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(
            [
                "ip",
                "hostnames",
                "os",
                "os_accuracy",
                "open_ports",
                "services",
                "related_domains",
                "harvester_data",
                "shodan_data",
                "enrichment_data",
            ]
        )

        for ip in sorted(bundle.hosts.keys(), key=_sort_key):
            entry = bundle.hosts[ip]
            hostnames = ";".join(entry.get("hostnames", []))
            osname = entry.get("os") or ""
            os_accuracy = entry.get("os_accuracy") or ""
            ports = ";".join(str(port) for port in entry.get("open_ports", []))
            # Flatten detailed service metadata into a single string so the CSV
            # remains easy to scan without losing critical fingerprint data.
            service_descriptions = []
            for service in entry.get("services", []) or []:
                if not isinstance(service, dict):
                    continue
                summary_parts = [
                    f"{service.get('port')}/{service.get('proto') or ''}".strip("/"),
                    service.get("service") or "",
                ]
                version = service.get("version")
                if version:
                    summary_parts.append(version)
                tunnel = service.get("tunnel")
                if tunnel:
                    summary_parts.append(f"tunnel={tunnel}")
                banner = service.get("banner")
                if banner:
                    summary_parts.append(f"banner={banner}")
                cpes = service.get("cpe") or []
                if cpes:
                    summary_parts.append(f"cpe={'|'.join(cpes)}")
                scripts = service.get("scripts") or []
                if scripts:
                    script_bits = []
                    for script in scripts:
                        if not isinstance(script, dict):
                            continue
                        script_id = script.get("id") or "script"
                        output = (script.get("output") or "").strip()
                        if output:
                            script_bits.append(f"{script_id}={output}")
                    if script_bits:
                        summary_parts.append(f"scripts={'|'.join(script_bits)}")
                nikto_findings = service.get("nikto_findings") or []
                if nikto_findings:
                    finding_bits: List[str] = []
                    for finding in nikto_findings:
                        if not isinstance(finding, Mapping):
                            continue
                        pieces: List[str] = []
                        risk = finding.get("risk")
                        if risk:
                            pieces.append(str(risk).upper())
                        description = finding.get("description")
                        if description:
                            pieces.append(str(description))
                        identifier = finding.get("id")
                        if identifier:
                            pieces.append(f"id={identifier}")
                        url = finding.get("url")
                        if url:
                            pieces.append(f"url={url}")
                        if pieces:
                            finding_bits.append(" ".join(pieces))
                    if finding_bits:
                        summary_parts.append(f"nikto={'|'.join(finding_bits)}")
                service_descriptions.append(" ".join(part for part in summary_parts if part))

            services = ";".join(service_descriptions)
            related_domains = ";".join(entry.get("related_domains", []))
            harvester_blob = ""
            harvester_data = entry.get("harvester")
            if harvester_data:
                try:
                    harvester_blob = json.dumps(harvester_data, sort_keys=True)
                except TypeError:
                    harvester_blob = str(harvester_data)

            shodan_blob = ""
            shodan_data = entry.get("shodan")
            if shodan_data:
                try:
                    shodan_blob = json.dumps(shodan_data, sort_keys=True)
                except TypeError:
                    shodan_blob = str(shodan_data)

            enrichment_blob = ""
            enrichment_data = entry.get("enrichment")
            if enrichment_data:
                try:
                    enrichment_blob = json.dumps(enrichment_data, sort_keys=True)
                except TypeError:
                    enrichment_blob = str(enrichment_data)

            writer.writerow(
                [
                    ip,
                    hostnames,
                    osname,
                    os_accuracy,
                    ports,
                    services,
                    related_domains,
                    harvester_blob,
                    shodan_blob,
                    enrichment_blob,
                ]
            )
    ensure_path_owner(Path(outpath))


def main() -> None:
    """Script entry point that wires together parsing, aggregation, and export."""

    parser = argparse.ArgumentParser(
        description=(
            "Merge Masscan, Nmap, theHarvester, and enrichment outputs into JSON and CSV "
            "inventory files."
        )
    )
    parser.add_argument("--nmap-dir", default="out/nmap", help="Directory with Nmap XML files.")
    parser.add_argument("--nikto-dir", default="out/nikto", help="Directory with Nikto JSON files.")
    parser.add_argument(
        "--masscan-json",
        default="out/masscan/masscan.json",
        help="Masscan JSON results file.",
    )
    parser.add_argument(
        "--smrib-json",
        default="out/smrib/smrib.json",
        help="JSON log produced by smrib.py (if used).",
    )
    parser.add_argument(
        "--harv-dir",
        default="out/harvester",
        help="Directory containing theHarvester text exports.",
    )
    parser.add_argument(
        "--dns-dir",
        default="out/dns",
        help="Directory containing DNS enumeration JSON files.",
    )
    parser.add_argument(
        "--banner-dir",
        default="out/banners",
        help="Directory containing banner grabbing JSON files.",
    )
    parser.add_argument(
        "--whois-dir",
        default="out/whois",
        help="Directory containing WHOIS lookup JSON files.",
    )
    parser.add_argument(
        "--ct-dir",
        default="out/certificate_transparency",
        help="Directory containing certificate transparency lookup JSON files.",
    )
    parser.add_argument(
        "--mac-dir",
        default="out/mac",
        help="Directory containing MAC address enrichment JSON files.",
    )
    parser.add_argument(
        "--shodan-dir",
        default="out/shodan",
        help="Directory containing Shodan lookup JSON files.",
    )
    parser.add_argument(
        "--out-json",
        default="out/report/inventory.json",
        help="Path for the merged JSON output.",
    )
    parser.add_argument(
        "--out-csv",
        default="out/report/inventory.csv",
        help="Path for the merged CSV output.",
    )

    args = parser.parse_args()

    masscan_results = parse_masscan_json(args.masscan_json)
    smrib_results = parse_smrib_json(args.smrib_json)
    nmap_results = parse_nmap_dir(args.nmap_dir)
    nikto_results = parse_nikto_dir(args.nikto_dir)
    harvester_results = parse_harvester_dir(args.harv_dir)
    dns_results = parse_dns_dir(args.dns_dir)
    banner_results = parse_banner_dir(args.banner_dir)
    whois_results = parse_whois_dir(args.whois_dir)
    ct_results = parse_ct_dir(args.ct_dir)
    mac_results = parse_mac_dir(args.mac_dir)
    shodan_results = parse_shodan_dir(args.shodan_dir)

    bundle = build_inventory(
        nmap_results,
        nikto_results,
        masscan_results,
        smrib_results,
        harvester_results,
        dns_results,
        banner_results,
        whois_results,
        ct_results,
        mac_results,
        shodan_results,
    )

    json_parent = os.path.dirname(args.out_json)
    if json_parent:
        os.makedirs(json_parent, exist_ok=True)
        ensure_path_owner(Path(json_parent), parents=True)
    csv_parent = os.path.dirname(args.out_csv)
    if csv_parent and csv_parent != json_parent:
        os.makedirs(csv_parent, exist_ok=True)
        ensure_path_owner(Path(csv_parent), parents=True)
    export_json(bundle, args.out_json)
    export_csv(bundle, args.out_csv)

    print(f"Wrote {args.out_json} and {args.out_csv}")

    def _sort_key(ip: str) -> tuple:
        try:
            return (0, ipaddress.ip_address(ip))
        except ValueError:
            return (1, ip)

    for ip in sorted(bundle.hosts, key=_sort_key):
        ports = sorted(
            {port for port in bundle.hosts[ip].get("open_ports", []) if port is not None}
        )
        if not ports:
            continue
        for port in ports:
            print(f"{ip} {port}")


if __name__ == "__main__":
    main()
